{
	"appsUsed":[
		
	],
	"createdTime":1758697780658,
	"deleted":false,
	"edges":[
		{
			"fromNodeId":"n_rkBif",
			"priority":0,
			"skip":false,
			"toNodeId":"n_6kZ3Q",
			"type":"next"
		},
		{
			"fromNodeId":"n_6kZ3Q",
			"priority":0,
			"skip":false,
			"toNodeId":"n_U2Pta",
			"type":"next"
		},
		{
			"fromNodeId":"n_U2Pta",
			"priority":0,
			"skip":false,
			"toNodeId":"n_7Meq5",
			"type":"next"
		}
	],
	"id":"68d3993487fd586922ab140b",
	"lastModifiedBy":45768,
	"lcName":"textexcel",
	"modifiedTime":1758699681351,
	"name":"TextExcel",
	"nodes":[
		{
			"context":{
				"appName":"callables",
				"resourceVersion":868,
				"resourceName":"callables_from_automation"
			},
			"debug":false,
			"dirty":false,
			"fallbackMode":"STOP",
			"groupId":"_s8Rjh-1",
			"id":"n_rkBif",
			"index":1,
			"inputs":{
				"result":{
					"type":"object",
					"additionalProperties":false,
					"properties":{
						"summary":{
							"type":"string",
							"title":"summary"
						}
					}
				},
				"setup":{
					"type":"object",
					"additionalProperties":false,
					"properties":{
						"file":{
							"type":"object",
							"title":"file"
						}
					}
				}
			},
			"skip":false,
			"subTitle":"Callable",
			"title":"Trigger via automation",
			"trigger":{
				"type":"CALLABLE"
			},
			"type":"START"
		},
		{
			"context":{
				"appName":"utility_by_unifyapps",
				"resourceVersion":0,
				"resourceName":"utility_by_unifyapps_generate_public_url",
				"type":"APPLICATION"
			},
			"debug":false,
			"dirty":false,
			"fallbackMode":"STOP",
			"groupId":"_s8Rjh-1",
			"id":"n_6kZ3Q",
			"index":2,
			"inputs":{
				"file":"{{ n_rkBif.outputs.file }}",
				"expiryTime":1
			},
			"skip":false,
			"subTitle":"Utility by UnifyApps",
			"title":"Generate public file URL",
			"type":"ACTION"
		},
		{
			"context":{
				"appName":"code_by_unifyapps",
				"resourceVersion":815,
				"resourceName":"code_by_unifyapps_python",
				"type":"APPLICATION"
			},
			"debug":false,
			"dirty":true,
			"fallbackMode":"STOP",
			"groupId":"_s8Rjh-1",
			"id":"n_U2Pta",
			"index":3,
			"inputs":{
				"output":{
					"type":"object",
					"additionalProperties":false,
					"properties":{
						"csvContent":{
							"type":"string",
							"title":"csvContent"
						}
					}
				},
				"input":{
					"type":"object",
					"additionalProperties":false,
					"properties":{
						"url":{
							"type":"string",
							"title":"url"
						}
					}
				},
				"configurationMode":"MANUAL",
				"code":"import sys, os, re, tempfile, urllib.request, urllib.parse\nfrom openpyxl import load_workbook\nimport pandas as pd\nimport itertools\n\n\ncsv_strings = []\n\nsrc = url\np = urllib.parse.urlparse(src)\nis_url = p.scheme in (\"http\", \"https\") and bool(p.netloc)\n\ntemp_path = None\nif is_url:\n    req = urllib.request.Request(src, headers={\"User-Agent\": \"Mozilla/5.0\"})\n    with urllib.request.urlopen(req) as resp:\n        cd = resp.headers.get(\"Content-Disposition\")\n        name = None\n        if cd:\n            parts = [x.strip() for x in cd.split(\";\")]\n            for part in parts:\n                low = part.lower()\n                if low.startswith(\"filename*=\"):\n                    try:\n                        val = part.split(\"=\", 1)[1]\n                        # filename*=UTF-8''name.xlsx\n                        enc, lang, fn = val.split(\"'\", 2)\n                        name = urllib.parse.unquote(fn)\n                        break\n                    except Exception:\n                        pass\n                if low.startswith(\"filename=\") and name is None:\n                    name = part.split(\"=\", 1)[1].strip().strip(\"\\\"'\")\n        if not name:\n            # Fallback to final URL path or original path\n            path_final = urllib.parse.urlparse(resp.geturl()).path or p.path\n            name = os.path.basename(path_final) or \"download.xlsx\"\n        base, ext = os.path.splitext(name)\n        if not ext:\n            ext = \".xlsx\"\n        suffix = ext.lower() if ext.lower() in (\".xlsx\", \".xlsm\", \".xltx\", \".xltm\") else \".xlsx\"\n        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tf:\n            tf.write(resp.read())\n            temp_path = tf.name\n    in_path = temp_path\n    base_name = base or \"download\"\nelse:\n    in_path = src\n    base_name = os.path.splitext(os.path.basename(in_path))[0]\n\n# Sanitize base name for output files\nbase_name = re.sub(r\"[\\\\/:*?\\\"<>|]\", \"_\", base_name).strip() or \"workbook\"\n\n# Load workbook (values only; formulas pre-evaluated if cached)\nwb = load_workbook(in_path, data_only=True, read_only=False)\nsheetnames = wb.sheetnames\n\nfor sname in sheetnames:\n    ws = wb[sname]\n\n    # Build raw grid\n    max_row = ws.max_row or 0\n    max_col = ws.max_column or 0\n    grid = [[None for _ in range(max_col)] for _ in range(max_row)]\n    r = 1\n    while r <= max_row:\n        row_vals = grid[r - 1]\n        c = 1\n        while c <= max_col:\n            row_vals[c - 1] = ws.cell(row=r, column=c).value\n            c += 1\n        r += 1\n\n    # Expand merged cells (copy top-left value)\n    for m in ws.merged_cells.ranges:\n        min_row, min_col, max_row_m, max_col_m = m.min_row, m.min_col, m.max_row, m.max_col\n        top_left = grid[min_row - 1][min_col - 1]\n        rr = min_row\n        while rr <= max_row_m:\n            cc = min_col\n            while cc <= max_col_m:\n                if grid[rr - 1][cc - 1] is None:\n                    grid[rr - 1][cc - 1] = top_left\n                cc += 1\n            rr += 1\n\n    # Drop completely empty rows\n    trimmed_rows = []\n    i = 0\n    while i < len(grid):\n        row = grid[i]\n        keep = False\n        j = 0\n        while j < len(row):\n            v = row[j]\n            if not (v is None or (isinstance(v, str) and v.strip() == \"\")):\n                keep = True\n                break\n            j += 1\n        if keep:\n            trimmed_rows.append(row)\n        i += 1\n    grid = trimmed_rows\n\n    # If nothing left, write empty CSV\n    if not grid:\n        safe_sname = re.sub(r\"[\\\\/:*?\\\"<>|]\", \"_\", sname).strip() or \"sheet\"\n        out_path = f\"{base_name}-{safe_sname}.csv\"\n        with open(out_path, \"w\", encoding=\"utf-8-sig\", newline=\"\") as f:\n            pass\n        continue\n\n    # Normalize row lengths (already equal by construction), then drop empty columns\n    n_cols = len(grid[0])\n    keep_cols = []\n    c = 0\n    while c < n_cols:\n        keep = False\n        r = 0\n        while r < len(grid):\n            v = grid[r][c]\n            if not (v is None or (isinstance(v, str) and v.strip() == \"\")):\n                keep = True\n                break\n            r += 1\n        if keep:\n            keep_cols.append(c)\n        c += 1\n    if len(keep_cols) < n_cols:\n        new_grid = []\n        r = 0\n        while r < len(grid):\n            row = grid[r]\n            new_row = []\n            for c in keep_cols:\n                new_row.append(row[c])\n            new_grid.append(new_row)\n            r += 1\n        grid = new_grid\n    if not grid or not grid[0]:\n        safe_sname = re.sub(r\"[\\\\/:*?\\\"<>|]\", \"_\", sname).strip() or \"sheet\"\n        out_path = f\"{base_name}-{safe_sname}.csv\"\n        with open(out_path, \"w\", encoding=\"utf-8-sig\", newline=\"\") as f:\n            pass\n        continue\n\n    # Guess header rows (1 or 2) using simple heuristic\n    header_rows_eff = 1\n    check_rows = grid[:2]\n    if len(check_rows) >= 2:\n        # fraction numeric row 0\n        vals0 = [v for v in check_rows[0] if not (v is None or (isinstance(v, str) and v.strip() == \"\"))]\n        nums0 = 0\n        for v in vals0:\n            if isinstance(v, (int, float)):\n                nums0 += 1\n        frac0 = (nums0 / len(vals0)) if vals0 else 0.0\n        # fraction numeric row 1\n        vals1 = [v for v in check_rows[1] if not (v is None or (isinstance(v, str) and v.strip() == \"\"))]\n        nums1 = 0\n        for v in vals1:\n            if isinstance(v, (int, float)):\n                nums1 += 1\n        frac1 = (nums1 / len(vals1)) if vals1 else 0.0\n        if frac0 < 0.3 and frac1 < 0.3:\n            header_rows_eff = 2\n\n    # Build headers by forward-filling each header row and joining parts\n    n_cols = len(grid[0])\n    header_block = []\n    hr_idx = 0\n    while hr_idx < min(header_rows_eff, len(grid)):\n        row = grid[hr_idx]\n        filled = []\n        last = None\n        j = 0\n        while j < n_cols:\n            v = row[j]\n            if not (v is None or (isinstance(v, str) and v.strip() == \"\")):\n                last = v\n            filled.append(last)\n            j += 1\n        header_block.append(filled)\n        hr_idx += 1\n\n    headers = []\n    c = 0\n    while c < n_cols:\n        parts = []\n        prev = None\n        r = 0\n        while r < len(header_block):\n            val = header_block[r][c]\n            if not (val is None or (isinstance(val, str) and str(val).strip() == \"\")):\n                s = str(val).strip()\n                if s and s != prev:\n                    parts.append(s)\n                    prev = s\n            r += 1\n        name = \" | \".join(parts).strip() if parts else f\"col{c+1}\"\n        headers.append(name)\n        c += 1\n\n    # Ensure unique headers\n    counts = {}\n    uniq_headers = []\n    i = 0\n    while i < len(headers):\n        h = headers[i]\n        if h in counts:\n            counts[h] += 1\n            uniq_headers.append(f\"{h}_{counts[h]-1}\")\n        else:\n            counts[h] = 1\n            uniq_headers.append(h)\n        i += 1\n\n    # Data rows below headers\n    data_rows = grid[header_rows_eff:] if header_rows_eff < len(grid) else []\n    df = pd.DataFrame(data_rows, columns=uniq_headers)\n\n    # Normalize empties and drop all-empty rows\n    df = df.replace(r\"^\\s*$\", pd.NA, regex=True)\n    df = df.dropna(how=\"all\").reset_index(drop=True)\n\n    # Write CSV\n    safe_sname = re.sub(r\"[\\\\/:*?\\\"<>|]\", \"_\", sname).strip() or \"sheet\"\n    out_path = f\"{base_name}-{safe_sname}.csv\"\n    df.to_csv(out_path, index=False, sep=\",\", encoding=\"utf-8-sig\", na_rep=\"\", lineterminator=\"\\n\")\n\n    csv_str = df.to_csv(index=False, sep=\",\", na_rep=\"\", lineterminator=\"\\n\")\n    csv_strings.append(csv_str)\n\nif temp_path and os.path.exists(temp_path):\n    try:\n        os.remove(temp_path)\n    except Exception:\n        pass\n\n# flat_csv_list = list(itertools.chain.from_iterable(csv_strings))\n\nresult = {\n    \"csv_strings\": csv_strings\n}",
				"imports":[
					"pandas",
					"openpyxl",
					"more-itertools"
				],
				"isAsync":false,
				"python_version":"3.12",
				"captureStdOutput":false,
				"parameters":{
					"url":"{{ n_6kZ3Q.outputs.url }}"
				}
			},
			"skip":false,
			"subTitle":"Code by UnifyApps",
			"title":"Execute Python script",
			"type":"ACTION"
		},
		{
			"context":{
				"appName":"callables",
				"resourceVersion":885,
				"resourceName":"callables_return_to_automation",
				"type":"APPLICATION"
			},
			"debug":false,
			"dirty":false,
			"fallbackMode":"STOP",
			"groupId":"_s8Rjh-1",
			"id":"n_7Meq5",
			"index":4,
			"inputs":{
				"result":{
					"summary":"{{ n_U2Pta.outputs.result.csvContent }}"
				}
			},
			"skip":false,
			"subTitle":"Callable",
			"title":"Respond to automation",
			"type":"STOP"
		}
	],
	"ownerUserId":45768,
	"schemaReferences":[
		
	],
	"settings":{
		"enableNodeLevelLogging":true,
		"enableRunLogging":true,
		"enableVariableLogging":true,
		"route":{
			"default":false,
			"tierName":"global"
		}
	},
	"standard":false,
	"tags":[
		
	],
	"version":10
}