{
	"appsUsed":[
		
	],
	"createdTime":1757435065929,
	"deleted":false,
	"edges":[
		{
			"fromNodeId":"n_vgfv1",
			"priority":0,
			"skip":false,
			"toNodeId":"n_hRNWr",
			"type":"next"
		},
		{
			"fromNodeId":"n_hRNWr",
			"priority":0,
			"skip":false,
			"toNodeId":"n_28GEh",
			"type":"next"
		},
		{
			"fromNodeId":"n_28GEh",
			"priority":0,
			"skip":false,
			"toNodeId":"n_po0sB",
			"type":"next"
		}
	],
	"id":"68c054b9ecdc557672b81d0f",
	"lastModifiedBy":39715,
	"lcName":"sumitbansaltesting",
	"modifiedTime":1759400683553,
	"name":"sumitBansalTesting",
	"nodes":[
		{
			"context":{
				"appName":"webhooks",
				"resourceVersion":809,
				"resourceName":"webhooks_default"
			},
			"debug":false,
			"dirty":false,
			"fallbackMode":"STOP",
			"groupId":"_hIm1D-1",
			"id":"n_vgfv1",
			"index":1,
			"inputs":{
				"request":{
					"contentType":"application/json"
				}
			},
			"skip":false,
			"subTitle":"Webhook",
			"title":"New event",
			"trigger":{
				"type":"WEBHOOK"
			},
			"type":"START"
		},
		{
			"context":{
				"appName":"code_by_unifyapps",
				"resourceVersion":880,
				"resourceName":"code_by_unifyapps_python",
				"type":"APPLICATION"
			},
			"debug":false,
			"dirty":true,
			"fallbackMode":"STOP",
			"groupId":"_hIm1D-1",
			"id":"n_hRNWr",
			"index":2,
			"inputs":{
				"configurationMode":"MANUAL",
				"code":"import asyncio\nimport json\nimport re\nimport base64\nfrom playwright.async_api import async_playwright\nfrom datetime import datetime\nfrom typing import Dict, Optional, Any\n\n\nclass LicenseDataExtractor:\n    \"\"\"Extracts specific license and real estate information\"\"\"\n    \n    def __init__(self):\n        self.target_fields = {\n            'issue_date': ['Issue Date', 'Issued Date', 'Date Issued', 'ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ•ÿµÿØÿßÿ±'],\n            'expiry_date': ['Expiry Date', 'Expiration Date', 'Valid Until', 'ÿ™ÿßÿ±ŸäÿÆ ÿßŸÜÿ™Ÿáÿßÿ° ÿßŸÑÿµŸÑÿßÿ≠Ÿäÿ©'],\n            'license_number': ['LicenseNumber', 'License No', 'License #', 'ÿ±ŸÇŸÖ ÿßŸÑÿ±ÿÆÿµÿ©'],\n            'real_estate_number': ['Real Estate #', 'Real Estate Number', 'Property #', 'ÿ±ŸÇŸÖ ÿßŸÑÿπŸÇÿßÿ±'],\n            'office_name': ['Office Name', 'Company Name', 'Business Name', 'ÿßÿ≥ŸÖ ÿßŸÑŸÖŸÉÿ™ÿ®', 'ÿßÿ≥ŸÖ ÿßŸÑÿ¥ÿ±ŸÉÿ©'],\n            'office_verified': ['Office Verified', 'Verified', 'Status', 'Verification Status', 'ÿ≠ÿßŸÑÿ© ÿßŸÑÿ™ÿ≠ŸÇŸÇ']\n        }\n    \n    def extract_field_by_patterns(self, text: str, field_name: str) -> Optional[str]:\n        \"\"\"Extract field value using multiple pattern matching strategies\"\"\"\n        \n        field_labels = self.target_fields.get(field_name, [])\n        \n        for label in field_labels:\n            # Pattern 1: Label followed by colon and value\n            pattern1 = rf'{re.escape(label)}\\s*:?\\s*([^\\n\\r,]+)'\n            match = re.search(pattern1, text, re.IGNORECASE | re.MULTILINE)\n            if match:\n                return match.group(1).strip()\n            \n            # Pattern 2: Label in same line with value\n            pattern2 = rf'{re.escape(label)}[:\\s]+([A-Za-z0-9\\-\\/\\s]+)'\n            match = re.search(pattern2, text, re.IGNORECASE)\n            if match:\n                return match.group(1).strip()\n        \n        return None\n    \n    def extract_dates(self, text: str) -> Dict[str, Optional[str]]:\n        \"\"\"Extract dates using date patterns\"\"\"\n        dates_found = {}\n        \n        # Common date patterns\n        date_patterns = [\n            r'\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{2,4}',  # DD/MM/YYYY or DD-MM-YYYY\n            r'\\d{2,4}[\\/\\-]\\d{1,2}[\\/\\-]\\d{1,2}',  # YYYY/MM/DD\n            r'\\d{1,2}\\s+[A-Za-z]{3,9}\\s+\\d{2,4}',  # DD Month YYYY\n            r'[A-Za-z]{3,9}\\s+\\d{1,2},?\\s+\\d{2,4}' # Month DD, YYYY\n        ]\n        \n        all_dates = []\n        for pattern in date_patterns:\n            matches = re.findall(pattern, text)\n            all_dates.extend(matches)\n        \n        # Try to assign dates to issue/expiry based on context\n        for date in all_dates:\n            # Look for context around the date\n            date_context = self._get_date_context(text, date)\n            \n            if any(word in date_context.lower() for word in ['issue', 'issued', 'start']):\n                dates_found['issue_date'] = date\n            elif any(word in date_context.lower() for word in ['expiry', 'expire', 'end', 'valid']):\n                dates_found['expiry_date'] = date\n        \n        return dates_found\n    \n    def _get_date_context(self, text: str, date: str) -> str:\n        \"\"\"Get text context around a date for better classification\"\"\"\n        date_index = text.find(date)\n        if date_index == -1:\n            return \"\"\n        \n        start = max(0, date_index - 50)\n        end = min(len(text), date_index + len(date) + 50)\n        return text[start:end]\n    \n    def extract_numbers(self, text: str) -> Dict[str, Optional[str]]:\n        \"\"\"Extract license and real estate numbers\"\"\"\n        numbers_found = {}\n        \n        # License number patterns\n        license_patterns = [\n            r'[Ll]icense\\s*[#:]?\\s*([A-Za-z0-9\\-\\/]+)',\n            r'[Ll]ic\\s*[#:]?\\s*([A-Za-z0-9\\-\\/]+)',\n            r'ÿ±ŸÇŸÖ ÿßŸÑÿ±ÿÆÿµÿ©\\s*:?\\s*([A-Za-z0-9\\-\\/]+)'\n        ]\n        \n        for pattern in license_patterns:\n            match = re.search(pattern, text)\n            if match:\n                numbers_found['license_number'] = match.group(1).strip()\n                break\n        \n        # Real estate number patterns\n        real_estate_patterns = [\n            r'[Rr]eal\\s+[Ee]state\\s*[#:]?\\s*([A-Za-z0-9\\-\\/]+)',\n            r'[Pp]roperty\\s*[#:]?\\s*([A-Za-z0-9\\-\\/]+)',\n            r'ÿ±ŸÇŸÖ ÿßŸÑÿπŸÇÿßÿ±\\s*:?\\s*([A-Za-z0-9\\-\\/]+)'\n        ]\n        \n        for pattern in real_estate_patterns:\n            match = re.search(pattern, text)\n            if match:\n                numbers_found['real_estate_number'] = match.group(1).strip()\n                break\n        \n        return numbers_found\n    \n    def extract_office_info(self, text: str) -> Dict[str, Optional[str]]:\n        \"\"\"Extract office name and verification status\"\"\"\n        office_info = {}\n        \n        # Office name patterns\n        office_patterns = [\n            r'Office Name\\s*:?\\s*([^\\n\\r,]+)',\n            r'Company Name\\s*:?\\s*([^\\n\\r,]+)',\n            r'Business Name\\s*:?\\s*([^\\n\\r,]+)',\n            r'ÿßÿ≥ŸÖ ÿßŸÑŸÖŸÉÿ™ÿ®\\s*:?\\s*([^\\n\\r,]+)',\n            r'ÿßÿ≥ŸÖ ÿßŸÑÿ¥ÿ±ŸÉÿ©\\s*:?\\s*([^\\n\\r,]+)'\n        ]\n        \n        for pattern in office_patterns:\n            match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)\n            if match:\n                office_name = match.group(1).strip()\n                # Clean up the office name (remove extra whitespace, special chars)\n                office_name = re.sub(r'\\s+', ' ', office_name)\n                office_info['office_name'] = office_name\n                break\n        \n        # Office verification patterns - convert to boolean\n        verification_patterns = [\n            r'Office Verified\\s*:?\\s*([^\\n\\r,]+)',\n            r'Verified\\s*:?\\s*([^\\n\\r,]+)',\n            r'Status\\s*:?\\s*([^\\n\\r,]+)',\n            r'Verification Status\\s*:?\\s*([^\\n\\r,]+)',\n            r'Office Status\\s*:?\\s*([^\\n\\r,]+)',\n            r'ÿ≠ÿßŸÑÿ© ÿßŸÑÿ™ÿ≠ŸÇŸÇ\\s*:?\\s*([^\\n\\r,]+)'\n        ]\n        \n        for pattern in verification_patterns:\n            match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)\n            if match:\n                verification_text = match.group(1).strip().lower()\n                \n                # Convert text to boolean - always return boolean, never raw text\n                # Use exact word matching to avoid false positives\n                positive_indicators = [\n                    r'\\bverified\\b', r'\\bactive\\b', r'\\byes\\b', r'\\btrue\\b', \n                    r'\\bvalid\\b', r'\\bapproved\\b', r'\\bconfirmed\\b', r'\\benabled\\b'\n                ]\n                negative_indicators = [\n                    r'\\bnot verified\\b', r'\\binactive\\b', r'\\bno\\b', r'\\bfalse\\b', \n                    r'\\binvalid\\b', r'\\brejected\\b', r'\\bdenied\\b', r'\\bsuspended\\b',\n                    r'\\bdisabled\\b', r'\\bexpired\\b', r'\\bcancelled\\b'\n                ]\n                \n                # Check negative patterns first (more specific)\n                if any(re.search(pattern, verification_text, re.IGNORECASE) for pattern in negative_indicators):\n                    office_info['office_verified'] = False\n                elif any(re.search(pattern, verification_text, re.IGNORECASE) for pattern in positive_indicators):\n                    office_info['office_verified'] = True\n                else:\n                    # Default to False if status is unclear or not explicitly verified\n                    office_info['office_verified'] = False\n                break\n        \n        return office_info\n    \n    async def check_office_verified_in_html(self, page) -> bool:\n        \"\"\"Check if 'office Verified' text exists anywhere in HTML - simple boolean logic\"\"\"\n        try:\n            # Get the full HTML content\n            html_content = await page.content()\n            \n            # Check if \"office Verified\" appears anywhere in HTML (case-insensitive)\n            office_verified_found = \"office verified\" in html_content.lower()\n            \n            return office_verified_found\n                \n        except Exception as e:\n            print(f\"   ‚ö†Ô∏è  HTML text check failed: {e}\")\n            return False\n    \n    async def capture_screenshot_base64(self, page) -> Optional[str]:\n        \"\"\"Capture page screenshot and convert to base64 string\"\"\"\n        try:\n            # Take screenshot and get as bytes\n            screenshot_bytes = await page.screenshot(\n                full_page=True,\n                type='png'\n            )\n            \n            # Convert to base64 string\n            screenshot_base64 = base64.b64encode(screenshot_bytes).decode('utf-8')\n            \n            # Add data URL prefix for complete base64 data URI\n            screenshot_data_uri = screenshot_base64\n            \n            return screenshot_data_uri\n            \n        except Exception as e:\n            print(f\"   ‚ö†Ô∏è  Screenshot capture failed: {e}\")\n            return None\n    \n    def extract_from_table(self, page) -> Dict[str, Optional[str]]:\n        \"\"\"Extract data from HTML table structures\"\"\"\n        extracted = {}\n        \n        try:\n            # Look for table rows with label-value pairs\n            rows = page.query_selector_all('tr, .row, .field-row')\n            \n            for row in rows:\n                row_text = row.inner_text()\n                \n                # Check if this row contains any of our target fields\n                for field_key, field_labels in self.target_fields.items():\n                    for label in field_labels:\n                        if label.lower() in row_text.lower():\n                            # Try to extract the value from this row\n                            value = self._extract_value_from_row(row_text, label)\n                            if value and field_key not in extracted:\n                                extracted[field_key] = value\n                                break\n        except:\n            pass\n        \n        return extracted\n    \n    def _extract_value_from_row(self, row_text: str, label: str) -> Optional[str]:\n        \"\"\"Extract value from a table row\"\"\"\n        # Split by common separators\n        for separator in [':', '\\t', '  ', ' - ']:\n            if separator in row_text:\n                parts = row_text.split(separator, 1)\n                if len(parts) == 2 and label.lower() in parts[0].lower():\n                    return parts[1].strip()\n        \n        return None\n\n\nasync def scrape_license_data(url: str) -> Dict[str, Any]:\n    \"\"\"\n    Scrape license and real estate data from the Dubai government page\n    \n    Args:\n        url (str): The URL to scrape\n        \n    Returns:\n        dict: Extracted license data\n    \"\"\"\n    \n    extractor = LicenseDataExtractor()\n    \n    async with async_playwright() as p:\n        # Launch browser with enhanced settings for government sites\n        browser = await p.chromium.launch(\n            headless=True,\n            args=[\n                '--disable-blink-features=AutomationControlled',\n                '--no-first-run',\n                '--disable-web-security',\n                '--no-sandbox'\n            ]\n        )\n        \n        # Create context with Dubai-specific settings\n        context = await browser.new_context(\n            viewport={'width': 1366, 'height': 768},\n            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n            locale='en-AE',\n            timezone_id='Asia/Dubai'\n        )\n        \n        page = await context.new_page()\n        \n        result = {\n            'url': url,\n            'timestamp': datetime.now().isoformat(),\n            'success': False,\n            'extracted_data': {\n                'issue_date': None,\n                'expiry_date': None,\n                'license_number': None,\n                'real_estate_number': None,\n                'office_name': None,\n                'office_verified': None,\n                'screenshot': None\n            },\n            'raw_data': {},\n            'extraction_methods': []\n        }\n        \n        try:\n            print(f\"üåê Loading: {url}\")\n            \n            # Navigate to page\n            await page.goto(url, wait_until='domcontentloaded', timeout=30000)\n            await page.wait_for_timeout(5000)  # Wait for dynamic content\n            \n            # Get page content\n            title = await page.title()\n            body_text = await page.inner_text('body')\n            html_content = await page.content()\n            \n            result['raw_data'] = {\n                'title': title,\n                'body_text': body_text,\n                'html_content': html_content,\n                'text_length': len(body_text)\n            }\n            \n            print(f\"üìù Extracted {len(body_text)} characters of text\")\n            \n            # Check if page loaded successfully\n            if len(body_text) < 50 or 'access denied' in body_text.lower():\n                print(\"‚ö†Ô∏è  Page appears to be blocked or has minimal content\")\n                result['status'] = 'blocked'\n                result['extracted_data']['raw_content'] = body_text\n                \n                # Still check for \"office Verified\" text even on blocked pages\n                print(\"üîç Checking for 'office Verified' text on blocked page...\")\n                try:\n                    office_verified_result = await extractor.check_office_verified_in_html(page)\n                    result['extracted_data']['office_verified'] = office_verified_result\n                    result['extraction_methods'].append('office_verified: html_text_search_blocked')\n                    found_status = \"found\" if office_verified_result else \"not found\"\n                    print(f\"   ‚úÖ 'office Verified' text {found_status} ‚Üí office_verified: {office_verified_result}\")\n                except Exception as e:\n                    print(f\"   ‚ùå HTML text search error: {e}\")\n                    result['extracted_data']['office_verified'] = False\n                \n                # Still capture screenshot for blocked pages (useful for debugging)\n                print(\"üì∏ Capturing screenshot of blocked page...\")\n                try:\n                    screenshot_base64 = await extractor.capture_screenshot_base64(page)\n                    if screenshot_base64:\n                        result['extracted_data']['screenshot'] = screenshot_base64\n                        result['extraction_methods'].append('screenshot: base64_capture_blocked')\n                        print(f\"   ‚úÖ Screenshot captured ({len(screenshot_base64)} chars)\")\n                    else:\n                        print(\"   ‚ùå Screenshot capture failed\")\n                except Exception as e:\n                    print(f\"   ‚ùå Screenshot error: {e}\")\n                \n                return result\n            \n            print(\"‚úÖ Page loaded successfully, extracting license data...\")\n            \n            # Capture screenshot first (before other extraction methods)\n            print(\"üì∏ Capturing page screenshot...\")\n            try:\n                screenshot_base64 = await extractor.capture_screenshot_base64(page)\n                if screenshot_base64:\n                    result['extracted_data']['screenshot'] = screenshot_base64\n                    result['extraction_methods'].append('screenshot: base64_capture')\n                    print(f\"   ‚úÖ Screenshot captured ({len(screenshot_base64)} chars)\")\n                else:\n                    print(\"   ‚ùå Screenshot capture failed\")\n            except Exception as e:\n                print(f\"   ‚ùå Screenshot error: {e}\")\n            \n            # Method 0: Check for \"office Verified\" text in HTML (primary method)\n            print(\"üîç Method 0: HTML text search for 'office Verified'\")\n            try:\n                office_verified_result = await extractor.check_office_verified_in_html(page)\n                result['extracted_data']['office_verified'] = office_verified_result\n                result['extraction_methods'].append('office_verified: html_text_search')\n                found_status = \"found\" if office_verified_result else \"not found\"\n                print(f\"   ‚úÖ 'office Verified' text {found_status} ‚Üí office_verified: {office_verified_result}\")\n            except Exception as e:\n                print(f\"   ‚ùå HTML text search error: {e}\")\n                # Set default value if method fails\n                result['extracted_data']['office_verified'] = False\n            \n            # Method 1: Pattern-based extraction from text (skip office_verified - handled by HTML search)\n            print(\"üîç Method 1: Text pattern matching\")\n            for field_name in result['extracted_data'].keys():\n                # Skip office_verified since it's handled by HTML text search method\n                if field_name in ['office_verified', 'screenshot']:\n                    continue\n                    \n                value = extractor.extract_field_by_patterns(body_text, field_name)\n                if value and not result['extracted_data'][field_name]:\n                    result['extracted_data'][field_name] = value\n                    result['extraction_methods'].append(f'{field_name}: text_pattern')\n                    print(f\"   Found {field_name}: {value}\")\n            \n            # Method 2: Date extraction\n            print(\"üîç Method 2: Date pattern matching\")\n            dates = extractor.extract_dates(body_text)\n            for date_type, date_value in dates.items():\n                if not result['extracted_data'][date_type]:\n                    result['extracted_data'][date_type] = date_value\n                    result['extraction_methods'].append(f'{date_type}: date_pattern')\n                    print(f\"   Found {date_type}: {date_value}\")\n            \n            # Method 3: Number extraction\n            print(\"üîç Method 3: Number pattern matching\")\n            numbers = extractor.extract_numbers(body_text)\n            for num_type, num_value in numbers.items():\n                if not result['extracted_data'][num_type]:\n                    result['extracted_data'][num_type] = num_value\n                    result['extraction_methods'].append(f'{num_type}: number_pattern')\n                    print(f\"   Found {num_type}: {num_value}\")\n            \n            # Method 3.5: Office info extraction (skip office_verified if already found by HTML text search)\n            print(\"üîç Method 3.5: Office info extraction\")\n            office_info = extractor.extract_office_info(body_text)\n            for office_type, office_value in office_info.items():\n                # Skip office_verified if we already got it from HTML text search method\n                if office_type == 'office_verified' and result['extracted_data']['office_verified'] is not None:\n                    print(f\"   ‚è≠Ô∏è  Skipping {office_type} (already found by HTML text search)\")\n                    continue\n                \n                if not result['extracted_data'][office_type]:\n                    result['extracted_data'][office_type] = office_value\n                    result['extraction_methods'].append(f'{office_type}: office_pattern')\n                    print(f\"   Found {office_type}: {office_value}\")\n            \n            # Method 4: Table-based extraction\n            print(\"üîç Method 4: Table structure extraction\")\n            try:\n                table_data = await extractor.extract_from_table(page)\n                for field, value in table_data.items():\n                    if not result['extracted_data'][field]:\n                        result['extracted_data'][field] = value\n                        result['extraction_methods'].append(f'{field}: table_extraction')\n                        print(f\"   Found {field}: {value}\")\n            except Exception as e:\n                print(f\"   Table extraction failed: {e}\")\n            \n            # Method 5: Form field extraction\n            print(\"üîç Method 5: Form field extraction\")\n            try:\n                inputs = await page.query_selector_all('input[value], select option[selected]')\n                for inp in inputs:\n                    name = await inp.get_attribute('name')\n                    value = await inp.get_attribute('value')\n                    if name and value:\n                        # Check if this field matches our targets\n                        for field_key, field_labels in extractor.target_fields.items():\n                            if any(label.lower().replace(' ', '').replace('#', '') in name.lower() \n                                   for label in field_labels):\n                                if not result['extracted_data'][field_key]:\n                                    result['extracted_data'][field_key] = value\n                                    result['extraction_methods'].append(f'{field_key}: form_field')\n                                    print(f\"   Found {field_key}: {value}\")\n                                break\n            except Exception as e:\n                print(f\"   Form extraction failed: {e}\")\n            \n            # Determine success\n            found_fields = [k for k, v in result['extracted_data'].items() \n                          if v is not None and k != 'screenshot']  # Don't count screenshot for success\n            result['success'] = len(found_fields) > 0\n            result['fields_found'] = len(found_fields)\n            \n            if result['success']:\n                print(f\"‚úÖ Successfully extracted {len(found_fields)} fields\")\n            else:\n                print(\"‚ùå No target fields found\")\n            \n        except Exception as e:\n            print(f\"‚ùå Error during extraction: {e}\")\n            result['error'] = str(e)\n        \n        finally:\n            await browser.close()\n        \n        return result\n\n\ndef print_extraction_results(result: Dict[str, Any]):\n    \"\"\"Print detailed extraction results\"\"\"\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"üìä LICENSE DATA EXTRACTION RESULTS\")\n    print(\"=\"*60)\n    \n    if result.get('error'):\n        print(f\"‚ùå Error: {result['error']}\")\n        return\n    \n    print(f\"‚úÖ Success: {result['success']}\")\n    print(f\"üéØ Fields Found: {result.get('fields_found', 0)}/6\")\n    print(f\"üìù Content Length: {result['raw_data']['text_length']} characters\")\n    \n    print(f\"\\nüîç EXTRACTED VALUES:\")\n    print(\"-\" * 40)\n    \n    extracted = result['extracted_data']\n    field_names = {\n        'issue_date': 'üìÖ Issue Date',\n        'expiry_date': '‚è∞ Expiry Date', \n        'license_number': 'üÜî License Number',\n        'real_estate_number': 'üè¢ Real Estate #',\n        'office_name': 'üèõÔ∏è Office Name',\n        'office_verified': '‚úÖ Office Verified',\n        'screenshot': 'üì∏ Screenshot'\n    }\n    \n    for field_key, display_name in field_names.items():\n        value = extracted.get(field_key)\n        if field_key == 'screenshot':\n            # Special handling for screenshot - show length instead of full content\n            if value:\n                status = \"‚úÖ\"\n                display_value = f\"Captured ({len(value)} characters)\"\n            else:\n                status = \"‚ùå\"\n                display_value = \"Not captured\"\n        elif field_key == 'office_verified':\n            # Special handling for boolean office_verified\n            if value is not None:\n                status = \"‚úÖ\"\n                display_value = str(value).lower()  # true/false\n            else:\n                status = \"‚ùå\"\n                display_value = \"Not found\"\n        else:\n            status = \"‚úÖ\" if value else \"‚ùå\"\n            display_value = value or 'Not found'\n        \n        print(f\"{status} {display_name}: {display_value}\")\n    \n    if result.get('extraction_methods'):\n        print(f\"\\nüîß Extraction Methods Used:\")\n        for method in result['extraction_methods']:\n            print(f\"   ‚Ä¢ {method}\")\n    \n    # Show raw content preview if blocked\n    if not result['success'] and extracted.get('raw_content'):\n        print(f\"\\nüìã Raw Content (blocked page):\")\n        print(\"-\" * 30)\n        print(extracted['raw_content'])\n        print(\"-\" * 30)\n\n\nasync def main(url):\n    \"\"\"Main execution function\"\"\"\n    \n    # url = \"https://trakheesi.dubailand.gov.ae/rev/m3xctf5b5h/f9zb41pjrb?cegaakad6n=NTI0Njc%3d\"\n    \n    print(\"üöÄ Dubai License Data Scraper\")\n    print(f\"üéØ Target: {url}\")\n    print(\"üîç Looking for: Issue Date, Expiry Date, License Number, Real Estate #, Office Name, Office Verified\")\n    print(\"üìù Office Verified: Searches for 'office Verified' text in HTML\")\n    print(\"üì∏ Also capturing: Full page screenshot (base64)\")\n    print(\"-\" * 80)\n    \n    # Extract license data\n    result = await scrape_license_data(url)\n    \n    # Save results\n    output_file = 'license_data_results.json'\n    with open(output_file, 'w', encoding='utf-8') as f:\n        json.dump(result, f, indent=2, ensure_ascii=False)\n    \n    print(f\"üíæ Results saved to: {output_file}\")\n    \n    # Print summary\n    print_extraction_results(result)\n    \n    return result\n\nimport subprocess\nimport sys\nsubprocess.check_call([sys.executable, \"-m\", \"playwright\", \"install\", \"chromium\"])\nurl = \"https://trakheesi.dubailand.gov.ae/rev/m3xctf5b5h/f9zb41pjrb?cegaakad6n=NTI0Njc%3d\"\n# Run the scraper\nresult = {\n    \"contents\": asyncio.run(main(url))\n}",
				"imports":[
					"playwright"
				],
				"isAsync":false,
				"python_version":"3.12",
				"captureStdOutput":false
			},
			"skip":false,
			"subTitle":"Code by UnifyApps",
			"title":"Execute Python script",
			"type":"ACTION"
		},
		{
			"additional":{
				"xsdSchemaConfig":{
					"root":{}
				}
			},
			"context":{
				"appName":"utility_by_unifyapps",
				"resourceVersion":0,
				"resourceName":"utility_by_unifyapps_to_json_object",
				"type":"APPLICATION"
			},
			"debug":false,
			"dirty":false,
			"fallbackMode":"STOP",
			"groupId":"_hIm1D-1",
			"id":"n_28GEh",
			"index":3,
			"inputs":{
				"jsonSchema":{
					"type":"array",
					"items":{
						"type":"object",
						"properties":{
							"name":{
								"type":"string",
								"title":"name"
							},
							"value":{
								"type":"string",
								"title":"value"
							}
						},
						"additionalProperties":false
					}
				},
				"jsonString":"\"[{\\\"name\\\":\\\"Virtu-Business-Public-sub-key\\\",\\\"value\\\":\\\"2f43f7d7982b42298a17bc98a8e77d4c\\\"},{\\\"name\\\":\\\"fusionUserName\\\",\\\"value\\\":\\\"fusionmwuser\\\"},{\\\"name\\\":\\\"fusionPassword\\\",\\\"value\\\":\\\"Welcome@123\\\"},{\\\"name\\\":\\\"Virtusa-Projects-Subscription-Key\\\",\\\"value\\\":\\\"d6f3f63f50854c0990cd61dbd7e64057\\\"},{\\\"name\\\":\\\"virtuIntegrationAppClientID\\\",\\\"value\\\":\\\"fb37e32e-cf16-434b-93e6-3420f7bc11f9\\\"},{\\\"name\\\":\\\"virtuIntegrationAppSecret\\\",\\\"value\\\":\\\"NDs8Q~QHYF7lHLNCcqs8iFFlFO3A0gain8YykdAu\\\"},{\\\"name\\\":\\\"virtuIntegrationAppAudiance\\\",\\\"value\\\":\\\"fb37e32e-cf16-434b-93e6-3420f7bc11f9\\\"},{\\\"name\\\":\\\"virtu-Integration-AD-Tenent\\\",\\\"value\\\":\\\"0d85160c-5899-44ca-acc8-db1501b993b6\\\"},{\\\"name\\\":\\\"RMPaasResourceId\\\",\\\"value\\\":\\\"fb37e32e-cf16-434b-93e6-3420f7bc11f9\\\"},{\\\"name\\\":\\\"RMPaasClientSecret\\\",\\\"value\\\":\\\"NDs8Q~QHYF7lHLNCcqs8iFFlFO3A0gain8YykdAu\\\"},{\\\"name\\\":\\\"RMPaasClientId\\\",\\\"value\\\":\\\"fb37e32e-cf16-434b-93e6-3420f7bc11f9\\\"},{\\\"name\\\":\\\"Virtu-Business-Internal-sub-key\\\",\\\"value\\\":\\\"2e75c34b7ee14a9c94f1703af8c850c7\\\"}]\""
			},
			"skip":false,
			"subTitle":"Utility by UnifyApps",
			"title":"Deserialise string to JSON object",
			"type":"ACTION"
		},
		{
			"context":{
				"appName":"code_by_unifyapps",
				"resourceVersion":0,
				"resourceName":"code_by_unifyapps_groovy",
				"type":"APPLICATION"
			},
			"debug":false,
			"dirty":false,
			"fallbackMode":"STOP",
			"groupId":"_hIm1D-1",
			"id":"n_po0sB",
			"index":4,
			"inputs":{
				"compile_static":false,
				"code":"assert false : \"Intentional failure\"\n"
			},
			"skip":false,
			"subTitle":"Code by WurkNow",
			"title":"Execute Groovy code",
			"type":"ACTION"
		}
	],
	"ownerUserId":39715,
	"schemaReferences":[
		
	],
	"settings":{
		"enableNodeLevelLogging":true,
		"enableRunLogging":true,
		"enableVariableLogging":true,
		"route":{
			"default":false,
			"tierName":"global"
		}
	},
	"standard":false,
	"tags":[
		
	],
	"version":5
}